## These are the steps to analyze the raw reads produced for the Transect and Temporal 16S amplicon libraries associated
## with the Department of Energy Hot Spots in Hot Moments in a brackish estuary funding 

### Location of the raw reads
### /workspace/cardonlab/DOE-TEMPORAL-AMPLICONS/Av4v5
### /workspace/cardonlab/DOE-TEMPORAL-AMPLICONS/Bv4v5
### /workspace/cardonlab/DOE-THS-TRANSECT/Av4v5
### /workspace/cardonlab/DOE-THS-TRANSECT/Bv4v5

## Each of these datasets will be error corrected and trimmed to the same length and then merged using the following basic commands from DADA2

    library(dada2)
    library(phyloseq)
    library(Biostrings)
    library(ggplot2)

    # set the path variable to the locationcontaing the fastq sequences
    path <- "/workspace/cardonlab/DOE-THS-TRANSECT/Av4v5"

    # Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
    fnFs <- sort(list.files(path, pattern="_R1.fastq", full.names = TRUE))
    fnRs <- sort(list.files(path, pattern="_R2.fastq", full.names = TRUE))

    sample.names <- sapply(strsplit(basename(fnFs), "_R1.fastq"), `[`, 1)

    filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
    filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
    names(filtFs) <- sample.names
    names(filtRs) <- sample.names

    out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(249,200),
                         maxN=5, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
                         compress=TRUE, multithread=TRUE)
  
    errF <- learnErrors(filtFs, multithread=TRUE)
    errR <- learnErrors(filtRs, multithread=TRUE)

    dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
    dadaRs <- dada(filtRs, err=errR, multithread=TRUE)

    mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
    seqtab <- makeSequenceTable(mergers)
    saveRDS(seqtab, "/workspace/cardonlab/DOE-THS-TRANSECT/Av4v5/Av4v5-seqtab.rds")

## Merge the Av4v5 and Bv4v5 transect and temporal datasets and then filter chimeras and write tax and OTU rds files for downstream analysis using phyloseq
## This work is conducted here /workspace/cardonlab/DOE-THS-TRANSECT/TRANSECT-TEMPORAL-COMBINED
## There is a script /workspace/cardonlab/DOE-THS-TRANSECT/TRANSECT-TEMPORAL-COMBINED/Av4v5/Av4v5-merge-dada2-runs.R that I used to merge the transect and temporal
## 16S merged sequences then filterd out the chimeras and the 

    library(dada2)
    # Merge multiple runs (if necessary)
    st1 <- readRDS("Av4v5-temporal-seqtab.rds")
    st2 <- readRDS("Av4v5-transect-seqtab.rds")

    st.all <- mergeSequenceTables(st1, st2)
    # Remove chimeras
    seqtab <- removeBimeraDenovo(st.all, method="consensus", multithread=TRUE)
    # Assign taxonomy
    tax <- assignTaxonomy(seqtab, "~/scripts/DBs/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
    # Write to disk
    saveRDS(seqtab, "seqtab-Av4v5-final.rds")
    saveRDS(tax, "seqtab-Av4v5-tax_final.rds")
